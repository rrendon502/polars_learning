{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 2: Carga de Datos - Archivos CSV con Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos CSV (Comma-Separated Values) son un formato estándar para el intercambio de datos tabulares. Polars ofrece una función `pl.read_csv()` altamente optimizada y flexible para leer estos archivos de manera eficiente.\n",
    "\n",
    "En este notebook, exploraremos las funcionalidades más comunes de `pl.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import polars as pl\n",
    "from io import StringIO # Para simular archivos en memoria\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Básico con Encabezado\n",
    "\n",
    "La forma más simple de leer un CSV es proporcionar la ruta al archivo (o un buffer, como `StringIO` para este ejemplo). Polars intentará inferir el separador, si tiene encabezado y los tipos de datos automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_data_con_header = \"col_a,col_b,col_c\\n1,a,true\\n2,b,false\\n3,c,true\"\n",
    "\n",
    "# Usamos StringIO para simular un archivo en memoria\n",
    "df_con_header = pl.read_csv(StringIO(csv_data_con_header))\n",
    "\n",
    "print(\"DataFrame leído desde CSV con encabezado:\")\n",
    "print(df_con_header)\n",
    "\n",
    "print(\"\\nGlimpse del DataFrame:\")\n",
    "df_con_header.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificar el Separador (`separator`)\n",
    "\n",
    "Aunque Polars es bueno infiriendo el separador, a veces es necesario especificarlo explícitamente, especialmente si el archivo usa un delimitador no estándar como punto y coma (`;`) o tabulaciones (`\\t`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_data_punto_y_coma = \"col_x;col_y;col_z\\n10;x;1.1\\n20;y;2.2\\n30;z;3.3\"\n",
    "\n",
    "df_punto_y_coma = pl.read_csv(StringIO(csv_data_punto_y_coma), separator=';')\n",
    "\n",
    "print(\"DataFrame leído desde CSV con separador punto y coma:\")\n",
    "print(df_punto_y_coma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Sin Encabezado (`has_header=False`)\n",
    "\n",
    "Si el archivo CSV no contiene una fila de encabezado, Polars, por defecto, tratará la primera línea como encabezado. Para evitar esto, se usa `has_header=False`. En este caso, Polars asignará nombres de columna genéricos como `column_1`, `column_2`, etc.\n",
    "\n",
    "Podemos proporcionar nuestros propios nombres de columna usando el parámetro `new_columns`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_data_sin_header = \"100,d,false\\n200,e,false\\n300,f,true\"\n",
    "\n",
    "# Leer CSV sin encabezado, Polars asigna nombres por defecto\n",
    "df_sin_header = pl.read_csv(StringIO(csv_data_sin_header), has_header=False)\n",
    "print(\"DataFrame sin encabezado (nombres por defecto):\")\n",
    "print(df_sin_header)\n",
    "\n",
    "# Leer CSV sin encabezado y asignar nombres personalizados\n",
    "df_sin_header_custom_names = pl.read_csv(\n",
    "    StringIO(csv_data_sin_header), \n",
    "    has_header=False, \n",
    "    new_columns=[\"id\", \"letra\", \"estado\"]\n",
    ")\n",
    "print(\"\\nDataFrame sin encabezado (nombres personalizados):\")\n",
    "print(df_sin_header_custom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar Columnas Específicas (`columns`)\n",
    "\n",
    "Para optimizar la carga, especialmente con archivos CSV muy anchos, podemos seleccionar solo un subconjunto de columnas. Esto se puede hacer proporcionando una lista de nombres de columna o una lista de índices de columna (0-based) al parámetro `columns`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reutilizamos csv_data_con_header: \"col_a,col_b,col_c\\n1,a,true\\n2,b,false\\n3,c,true\"\n",
    "\n",
    "# Seleccionar columnas por nombre\n",
    "df_cols_seleccionadas_nombre = pl.read_csv(StringIO(csv_data_con_header), columns=[\"col_a\", \"col_c\"])\n",
    "print(\"Selección de columnas por nombre (['col_a', 'col_c']):\")\n",
    "print(df_cols_seleccionadas_nombre)\n",
    "\n",
    "# Seleccionar columnas por índice (0-based)\n",
    "df_cols_seleccionadas_indice = pl.read_csv(StringIO(csv_data_con_header), columns=[0, 2]) # col_a y col_c\n",
    "print(\"\\nSelección de columnas por índice ([0, 2]):\")\n",
    "print(df_cols_seleccionadas_indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitar Número de Filas (`n_rows`) y Omitir Filas (`skip_rows`)\n",
    "\n",
    "- `n_rows`: Útil para leer solo las primeras `N` filas de un archivo, ideal para inspecciones rápidas de archivos grandes sin cargar todo en memoria.\n",
    "- `skip_rows`: Permite omitir un número específico de filas desde el inicio del archivo. Esto es útil si el archivo CSV contiene metadatos o líneas de comentarios al principio que no son parte de los datos tabulares."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reutilizamos csv_data_con_header: \"col_a,col_b,col_c\\n1,a,true\\n2,b,false\\n3,c,true\"\n",
    "\n",
    "# Leer solo las primeras 2 filas\n",
    "df_n_rows = pl.read_csv(StringIO(csv_data_con_header), n_rows=2)\n",
    "print(\"Leyendo solo las primeras 2 filas (n_rows=2):\")\n",
    "print(df_n_rows)\n",
    "\n",
    "# Simular un CSV con líneas de metadatos al inicio\n",
    "csv_data_con_skip = \"metadata_line_1\\nmetadata_line_2\\ncol_1,col_2\\nval1,val2\\nval3,val4\"\n",
    "\n",
    "# Omitir las primeras 2 filas (las líneas de metadatos)\n",
    "df_skip_rows = pl.read_csv(StringIO(csv_data_con_skip), skip_rows=2)\n",
    "print(\"\\nOmitiendo las 2 primeras filas (skip_rows=2):\")\n",
    "print(df_skip_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Datos (`dtypes` o `schema`)\n",
    "\n",
    "Especificar los tipos de datos es crucial para la correctitud de los datos y la eficiencia de la memoria y el procesamiento. Aunque Polars tiene una inferencia de tipos robusta, hay casos donde es preferible definir los tipos explícitamente.\n",
    "\n",
    "- `dtypes`: Se puede pasar un diccionario donde las claves son nombres de columna y los valores son los tipos de Polars deseados (e.g., `pl.Int32`, `pl.Float64`, `pl.Utf8`, `pl.Boolean`, `pl.Date`). Las columnas no especificadas en el diccionario seguirán la inferencia automática.\n",
    "- `schema`: Similar a `dtypes`, pero puede ser una lista de tipos si se conocen todas las columnas en orden, o un diccionario. Es más flexible si se quiere renombrar columnas y especificar tipos al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reutilizamos csv_data_con_header: \"col_a,col_b,col_c\\n1,a,true\\n2,b,false\\n3,c,true\"\n",
    "# Por defecto, Polars infiere: col_a: Int64, col_b: Utf8, col_c: Boolean\n",
    "print(\"Tipos inferidos por defecto:\")\n",
    "pl.read_csv(StringIO(csv_data_con_header)).glimpse()\n",
    "\n",
    "# Forzar col_a a Float32 y col_c a Utf8 (string)\n",
    "custom_dtypes = {\n",
    "    \"col_a\": pl.Float32, \n",
    "    \"col_c\": pl.Utf8\n",
    "}\n",
    "\n",
    "df_custom_dtypes = pl.read_csv(StringIO(csv_data_con_header), dtypes=custom_dtypes)\n",
    "\n",
    "print(\"\\nTipos con dtypes personalizados:\")\n",
    "df_custom_dtypes.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de Valores Nulos (`null_values`)\n",
    "\n",
    "Por defecto, Polars interpreta las cadenas vacías (`\"\"`) como cadenas vacías literales, no como valores nulos. Si tu CSV usa cadenas específicas para representar datos faltantes (e.g., `\"NA\"`, `\"missing\"`, `\"-\"`), puedes indicárselo a Polars mediante el parámetro `null_values`.\n",
    "\n",
    "`null_values` puede ser:\n",
    "- Una cadena: `null_values=\"NA\"` (ese string se interpretará como nulo en todas las columnas).\n",
    "- Una lista de cadenas: `null_values=[\"NA\", \"N/A\", \"-\"]` (cualquiera de estos strings se interpretará como nulo).\n",
    "- Un diccionario: `null_values={\"columna_X\": \"missing\", \"columna_Y\": \"\"}` (define valores nulos específicos por columna)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_data_con_nulos = \"id,valor,desc\\n1,10,ok\\n2,NA,error\\n3,,ok\\n4,30,missing\"\n",
    "\n",
    "# Comportamiento por defecto: \"NA\" y \"missing\" son strings, \"\" es string vacío\n",
    "df_nulos_defecto = pl.read_csv(StringIO(csv_data_con_nulos))\n",
    "print(\"Nulos por defecto (conteo de nulos por columna):\")\n",
    "print(df_nulos_defecto.null_count())\n",
    "print(df_nulos_defecto) # Observa los valores\n",
    "\n",
    "# Especificar \"NA\" como valor nulo para todas las columnas\n",
    "df_nulos_na = pl.read_csv(StringIO(csv_data_con_nulos), null_values=\"NA\")\n",
    "print(\"\\nNulos con null_values='NA':\")\n",
    "print(df_nulos_na.is_null()) # Muestra una máscara booleana de nulos\n",
    "print(df_nulos_na.null_count())\n",
    "\n",
    "# Especificar una lista de valores nulos para todas las columnas\n",
    "df_nulos_multi = pl.read_csv(StringIO(csv_data_con_nulos), null_values=[\"NA\", \"missing\", \"\"])\n",
    "print(\"\\nNulos con null_values=['NA', 'missing', '']:\")\n",
    "print(df_nulos_multi.is_null())\n",
    "print(df_nulos_multi.null_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen y Próximos Pasos\n",
    "\n",
    "Hemos cubierto los parámetros más importantes de `pl.read_csv()` para cargar y parsear archivos CSV de manera efectiva. Polars ofrece muchos más parámetros para situaciones más complejas, como:\n",
    "- `encoding`: Para especificar la codificación del archivo (e.g., `'utf-8'`, `'latin1'`, `'iso-8859-1'`).\n",
    "- `comment_char`: Para especificar un carácter que indica que el resto de la línea es un comentario y debe ser ignorado.\n",
    "- `low_memory`: Reduce el uso de memoria a costa de, potencialmente, leer el archivo en múltiples chunks (puede afectar el rendimiento y la inferencia de tipos si los chunks son muy diferentes).\n",
    "- `ignore_errors`: Si es `True`, Polars intentará omitir las filas que no se puedan parsear correctamente. Por defecto es `False`, lo que significa que un error de parseo detendrá la operación.\n",
    "- `try_parse_dates`: Intenta parsear automáticamente columnas que parezcan fechas/horas.\n",
    "\n",
    "En los siguientes apartados y notebooks, exploraremos cómo guardar DataFrames y cómo trabajar con otros formatos de archivo como Parquet y Excel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
